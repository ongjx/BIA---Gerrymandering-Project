{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import bs4 as bs\n",
    "import urllib.request #Scraping\n",
    "import re #Preprocessing\n",
    "import nltk #Tokenizing\n",
    "from nltk.corpus import stopwords #Don't consider stopwords in histogram\n",
    "\n",
    "import heapq #getting the top k largest sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettings the data source\n",
    "source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Global_warming').read()\n",
    "\n",
    "# Parsing the data/ creating BeautifulSoup object\n",
    "soup = bs.BeautifulSoup(source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the data\n",
    "text = \"\"\n",
    "for paragraph in soup.find_all('p'):\n",
    "    text += paragraph.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)  #Remove the references \"[1][2]\" etc.\n",
    "text = re.sub(r'\\s+',' ',text)  #Replace the multiple spaces with 1 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = text.lower()\n",
    "clean_text = re.sub(r'\\W', ' ', clean_text)   #Delete all non-word characters (punctuations)\n",
    "clean_text = re.sub(r'\\d', ' ', clean_text)   #Remove digits\n",
    "    \n",
    "#Separated clean_text from text because histogram will be built on clean_text\n",
    "#Whereas the output will be in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "for word in nltk.word_tokenize(clean_text):\n",
    "    if word not in stop_words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the weighted histogram\n",
    "#Divide all values by maximum value\n",
    "maxCount = max(word2count.values())\n",
    "for key in word2count.keys():\n",
    "    word2count[key] = word2count[key]/maxCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2score = {}\n",
    "sentCount=0\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if(len(sentence.split(' ')) < 25):  #Sent < 30 words\n",
    "            #Check such that it's not biased towards long sentences over important sentences\n",
    "            if word in word2count.keys():\n",
    "                sentCount+=word2count[word]\n",
    "            else:\n",
    "                sentCount+=0\n",
    "    sent2score[sentence] = sentCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284]\n",
      "In 1986 and November 1987, NASA climate scientist James Hansen gave testimony to Congress on global warming.\n",
      "There were increasing heatwaves and drought problems in the summer of 1988, and when Hansen testified in the Senate on 23 June he sparked worldwide interest.\n",
      "[283] He said, \"global warming has reached a level such that we can ascribe with a high degree of confidence a cause and effect relationship between the greenhouse effect and the observed warming.\n",
      "\"[285] Public attention increased over the summer, and global warming became the dominant popular term, commonly used both by the press and in public discourse.\n",
      "[284]\n",
      "In a 2008 NASA article on usage, Erik M. Conway defined global warming as \"the increase in Earth's average surface temperature due to rising levels of greenhouse gases\", while climate change was \"a long-term change in the Earth's climate, or of a region on Earth\".\n"
     ]
    }
   ],
   "source": [
    "# Getting summary\n",
    "\n",
    "best_sentences = heapq.nlargest(5, sent2score, key=sent2score.get)\n",
    "\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
